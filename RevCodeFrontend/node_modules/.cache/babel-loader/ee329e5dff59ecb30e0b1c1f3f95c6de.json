{"ast":null,"code":"var _jsxFileName = \"/Users/finality5/Desktop/RevCode/RevCodeFrontend/src/Speech.js\";\nimport React, { Component } from \"react\";\nimport { Button, Message } from \"semantic-ui-react\";\nimport axios from \"axios\";\nwindow.SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;\nlet finalTranscript = \"\";\nlet recognition = new window.SpeechRecognition(); //recognition.lang = \"en-US\";\n\nrecognition.lang = \"th-TH\";\nrecognition.interimResults = true;\nrecognition.maxAlternatives = 10;\nrecognition.continuous = true;\nexport class Speech extends Component {\n  constructor(...args) {\n    super(...args);\n    this.state = {\n      pressed: false,\n      res: \"\"\n    };\n\n    this.btnPressed = () => {\n      this.setState({\n        pressed: !this.state.pressed\n      });\n\n      if (this.state.pressed && window.hasOwnProperty(\"webkitSpeechRecognition\")) {\n        recognition.onresult = event => {\n          let interimTranscript = \"\";\n\n          for (let i = event.resultIndex, len = event.results.length; i < len; i++) {\n            let transcript = event.results[i][0].transcript;\n\n            if (event.results[i].isFinal) {\n              finalTranscript += transcript;\n            } else {\n              interimTranscript += transcript;\n            }\n          }\n\n          this.setState({\n            res: finalTranscript + interimTranscript\n          });\n          axios.post(\"http://127.0.0.1:5000/\", {\n            res: finalTranscript + interimTranscript\n          }).then(res => {\n            console.log(\"####\", res);\n          });\n        };\n\n        recognition.start();\n      } else {\n        recognition.stop();\n        alert(\"Stop recording\");\n      }\n    };\n  }\n\n  render() {\n    console.log(this.state.res);\n    return React.createElement(\"div\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 54\n      },\n      __self: this\n    }, React.createElement(Button, {\n      content: !this.state.pressed ? \"Start Record\" : \"Recording\",\n      icon: \"microphone\",\n      color: !this.state.pressed ? \"teal\" : \"red\",\n      labelPosition: \"left\",\n      onClick: this.btnPressed,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 55\n      },\n      __self: this\n    }), React.createElement(Message, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 62\n      },\n      __self: this\n    }, React.createElement(Message.Header, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 63\n      },\n      __self: this\n    }, \"Result\"), React.createElement(\"p\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 64\n      },\n      __self: this\n    }, this.state.res)));\n  }\n\n}\nexport default Speech;","map":{"version":3,"sources":["/Users/finality5/Desktop/RevCode/RevCodeFrontend/src/Speech.js"],"names":["React","Component","Button","Message","axios","window","SpeechRecognition","webkitSpeechRecognition","finalTranscript","recognition","lang","interimResults","maxAlternatives","continuous","Speech","state","pressed","res","btnPressed","setState","hasOwnProperty","onresult","event","interimTranscript","i","resultIndex","len","results","length","transcript","isFinal","post","then","console","log","start","stop","alert","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,SAASC,MAAT,EAAiBC,OAAjB,QAAgC,mBAAhC;AACA,OAAOC,KAAP,MAAkB,OAAlB;AAEAC,MAAM,CAACC,iBAAP,GACED,MAAM,CAACE,uBAAP,IAAkCF,MAAM,CAACC,iBAD3C;AAEA,IAAIE,eAAe,GAAG,EAAtB;AACA,IAAIC,WAAW,GAAG,IAAIJ,MAAM,CAACC,iBAAX,EAAlB,C,CACA;;AACAG,WAAW,CAACC,IAAZ,GAAmB,OAAnB;AACAD,WAAW,CAACE,cAAZ,GAA6B,IAA7B;AACAF,WAAW,CAACG,eAAZ,GAA8B,EAA9B;AACAH,WAAW,CAACI,UAAZ,GAAyB,IAAzB;AACA,OAAO,MAAMC,MAAN,SAAqBb,SAArB,CAA+B;AAAA;AAAA;AAAA,SACpCc,KADoC,GAC5B;AAAEC,MAAAA,OAAO,EAAE,KAAX;AAAkBC,MAAAA,GAAG,EAAE;AAAvB,KAD4B;;AAAA,SAEpCC,UAFoC,GAEvB,MAAM;AACjB,WAAKC,QAAL,CAAc;AAAEH,QAAAA,OAAO,EAAE,CAAC,KAAKD,KAAL,CAAWC;AAAvB,OAAd;;AACA,UAAI,KAAKD,KAAL,CAAWC,OAAX,IAAsBX,MAAM,CAACe,cAAP,CAAsB,yBAAtB,CAA1B,EAA4E;AAC1EX,QAAAA,WAAW,CAACY,QAAZ,GAAuBC,KAAK,IAAI;AAC9B,cAAIC,iBAAiB,GAAG,EAAxB;;AACA,eACE,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAd,EAA2BC,GAAG,GAAGJ,KAAK,CAACK,OAAN,CAAcC,MADjD,EAEEJ,CAAC,GAAGE,GAFN,EAGEF,CAAC,EAHH,EAIE;AACA,gBAAIK,UAAU,GAAGP,KAAK,CAACK,OAAN,CAAcH,CAAd,EAAiB,CAAjB,EAAoBK,UAArC;;AACA,gBAAIP,KAAK,CAACK,OAAN,CAAcH,CAAd,EAAiBM,OAArB,EAA8B;AAC5BtB,cAAAA,eAAe,IAAIqB,UAAnB;AACD,aAFD,MAEO;AACLN,cAAAA,iBAAiB,IAAIM,UAArB;AACD;AACF;;AACD,eAAKV,QAAL,CAAc;AAAEF,YAAAA,GAAG,EAAET,eAAe,GAAGe;AAAzB,WAAd;AAEAnB,UAAAA,KAAK,CACF2B,IADH,CACQ,wBADR,EACkC;AAC9Bd,YAAAA,GAAG,EAAET,eAAe,GAAGe;AADO,WADlC,EAIGS,IAJH,CAIQf,GAAG,IAAI;AACXgB,YAAAA,OAAO,CAACC,GAAR,CAAY,MAAZ,EAAoBjB,GAApB;AACD,WANH;AAOD,SAvBD;;AAwBAR,QAAAA,WAAW,CAAC0B,KAAZ;AACD,OA1BD,MA2BI;AACF1B,QAAAA,WAAW,CAAC2B,IAAZ;AACAC,QAAAA,KAAK,CAAC,gBAAD,CAAL;AACD;AACF,KAnCmC;AAAA;;AAoCpCC,EAAAA,MAAM,GAAG;AACPL,IAAAA,OAAO,CAACC,GAAR,CAAY,KAAKnB,KAAL,CAAWE,GAAvB;AAEA,WACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,MAAD;AACE,MAAA,OAAO,EAAE,CAAC,KAAKF,KAAL,CAAWC,OAAZ,GAAsB,cAAtB,GAAuC,WADlD;AAEE,MAAA,IAAI,EAAC,YAFP;AAGE,MAAA,KAAK,EAAE,CAAC,KAAKD,KAAL,CAAWC,OAAZ,GAAsB,MAAtB,GAA+B,KAHxC;AAIE,MAAA,aAAa,EAAC,MAJhB;AAKE,MAAA,OAAO,EAAE,KAAKE,UALhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAQE,oBAAC,OAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,OAAD,CAAS,MAAT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,EAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAI,KAAKH,KAAL,CAAWE,GAAf,CAFF,CARF,CADF;AAeD;;AAtDmC;AAyDtC,eAAeH,MAAf","sourcesContent":["import React, { Component } from \"react\";\nimport { Button, Message } from \"semantic-ui-react\";\nimport axios from \"axios\";\n\nwindow.SpeechRecognition =\n  window.webkitSpeechRecognition || window.SpeechRecognition;\nlet finalTranscript = \"\";\nlet recognition = new window.SpeechRecognition();\n//recognition.lang = \"en-US\";\nrecognition.lang = \"th-TH\";\nrecognition.interimResults = true;\nrecognition.maxAlternatives = 10;\nrecognition.continuous = true;\nexport class Speech extends Component {\n  state = { pressed: false, res: \"\" };\n  btnPressed = () => {\n    this.setState({ pressed: !this.state.pressed });\n    if (this.state.pressed && window.hasOwnProperty(\"webkitSpeechRecognition\")) {\n      recognition.onresult = event => {\n        let interimTranscript = \"\";\n        for (\n          let i = event.resultIndex, len = event.results.length;\n          i < len;\n          i++\n        ) {\n          let transcript = event.results[i][0].transcript;\n          if (event.results[i].isFinal) {\n            finalTranscript += transcript;\n          } else {\n            interimTranscript += transcript;\n          }\n        }\n        this.setState({ res: finalTranscript + interimTranscript });\n\n        axios\n          .post(\"http://127.0.0.1:5000/\", {\n            res: finalTranscript + interimTranscript\n          })\n          .then(res => {\n            console.log(\"####\", res);\n          });\n      };\n      recognition.start();\n    }\n    else{\n      recognition.stop();\n      alert(\"Stop recording\")\n    }\n  };\n  render() {\n    console.log(this.state.res);\n\n    return (\n      <div>\n        <Button\n          content={!this.state.pressed ? \"Start Record\" : \"Recording\"}\n          icon=\"microphone\"\n          color={!this.state.pressed ? \"teal\" : \"red\"}\n          labelPosition=\"left\"\n          onClick={this.btnPressed}\n        />\n        <Message>\n          <Message.Header>Result</Message.Header>\n          <p>{this.state.res}</p>\n        </Message>\n      </div>\n    );\n  }\n}\n\nexport default Speech;\n"]},"metadata":{},"sourceType":"module"}