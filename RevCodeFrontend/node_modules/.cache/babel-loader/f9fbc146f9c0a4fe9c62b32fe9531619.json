{"ast":null,"code":"var _jsxFileName = \"/Users/finality5/Desktop/speechreg/src/Speech.js\";\nimport React, { Component } from \"react\";\nimport { Button, Message } from \"semantic-ui-react\";\nimport axios from 'axios';\nwindow.SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;\nlet finalTranscript = \"\";\nlet recognition = new window.SpeechRecognition();\nrecognition.lang = \"en-US\";\nrecognition.lang = \"th-TH\";\nrecognition.interimResults = true;\nrecognition.maxAlternatives = 10;\nrecognition.continuous = true;\nexport class Speech extends Component {\n  constructor(...args) {\n    super(...args);\n    this.state = {\n      pressed: false,\n      res: \"\"\n    };\n\n    this.btnPressed = () => {\n      this.setState({\n        pressed: !this.state.pressed\n      });\n\n      if (window.hasOwnProperty('webkitSpeechRecognition')) {\n        recognition.onresult = event => {\n          let interimTranscript = \"\";\n\n          for (let i = event.resultIndex, len = event.results.length; i < len; i++) {\n            let transcript = event.results[i][0].transcript;\n\n            if (event.results[i].isFinal) {\n              finalTranscript += transcript;\n            } else {\n              interimTranscript += transcript;\n            }\n          }\n\n          this.setState({\n            res: finalTranscript + interimTranscript\n          });\n        };\n\n        recognition.start();\n      }\n      /*else{\n        recognition.stop();\n        alert(\"Stop recording\")\n      }*/\n\n\n      const sendData = this.state.res;\n      axios.post(\"http://127.0.0.1:5000/\", {\n        sendData\n      }).then(res => {\n        console.log(\"####\", res);\n      });\n    };\n  }\n\n  render() {\n    console.log(this.state.res);\n    return React.createElement(\"div\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 53\n      },\n      __self: this\n    }, React.createElement(Button, {\n      content: !this.state.pressed ? \"Start Record\" : \"Recording\",\n      icon: \"microphone\",\n      color: !this.state.pressed ? \"teal\" : \"red\",\n      labelPosition: \"left\",\n      onClick: this.btnPressed,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 54\n      },\n      __self: this\n    }), React.createElement(Message, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 61\n      },\n      __self: this\n    }, React.createElement(Message.Header, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 62\n      },\n      __self: this\n    }, \"Result\"), React.createElement(\"p\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 63\n      },\n      __self: this\n    }, this.state.res)));\n  }\n\n}\nexport default Speech;","map":{"version":3,"sources":["/Users/finality5/Desktop/speechreg/src/Speech.js"],"names":["React","Component","Button","Message","axios","window","SpeechRecognition","webkitSpeechRecognition","finalTranscript","recognition","lang","interimResults","maxAlternatives","continuous","Speech","state","pressed","res","btnPressed","setState","hasOwnProperty","onresult","event","interimTranscript","i","resultIndex","len","results","length","transcript","isFinal","start","sendData","post","then","console","log","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,SAASC,MAAT,EAAiBC,OAAjB,QAAgC,mBAAhC;AACA,OAAOC,KAAP,MAAkB,OAAlB;AAEAC,MAAM,CAACC,iBAAP,GACED,MAAM,CAACE,uBAAP,IAAkCF,MAAM,CAACC,iBAD3C;AAEA,IAAIE,eAAe,GAAG,EAAtB;AACA,IAAIC,WAAW,GAAG,IAAIJ,MAAM,CAACC,iBAAX,EAAlB;AACAG,WAAW,CAACC,IAAZ,GAAmB,OAAnB;AACAD,WAAW,CAACC,IAAZ,GAAmB,OAAnB;AACAD,WAAW,CAACE,cAAZ,GAA6B,IAA7B;AACAF,WAAW,CAACG,eAAZ,GAA8B,EAA9B;AACAH,WAAW,CAACI,UAAZ,GAAyB,IAAzB;AACA,OAAO,MAAMC,MAAN,SAAqBb,SAArB,CAA+B;AAAA;AAAA;AAAA,SACpCc,KADoC,GAC5B;AAAEC,MAAAA,OAAO,EAAE,KAAX;AAAkBC,MAAAA,GAAG,EAAE;AAAvB,KAD4B;;AAAA,SAEpCC,UAFoC,GAEvB,MAAM;AACjB,WAAKC,QAAL,CAAc;AAAEH,QAAAA,OAAO,EAAE,CAAC,KAAKD,KAAL,CAAWC;AAAvB,OAAd;;AACA,UAAIX,MAAM,CAACe,cAAP,CAAsB,yBAAtB,CAAJ,EAAsD;AACpDX,QAAAA,WAAW,CAACY,QAAZ,GAAuBC,KAAK,IAAI;AAC9B,cAAIC,iBAAiB,GAAG,EAAxB;;AACA,eACE,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAd,EAA2BC,GAAG,GAAGJ,KAAK,CAACK,OAAN,CAAcC,MADjD,EAEEJ,CAAC,GAAGE,GAFN,EAGEF,CAAC,EAHH,EAIE;AACA,gBAAIK,UAAU,GAAGP,KAAK,CAACK,OAAN,CAAcH,CAAd,EAAiB,CAAjB,EAAoBK,UAArC;;AACA,gBAAIP,KAAK,CAACK,OAAN,CAAcH,CAAd,EAAiBM,OAArB,EAA8B;AAC5BtB,cAAAA,eAAe,IAAIqB,UAAnB;AACD,aAFD,MAEO;AACLN,cAAAA,iBAAiB,IAAIM,UAArB;AACD;AACF;;AACD,eAAKV,QAAL,CAAc;AAAEF,YAAAA,GAAG,EAAET,eAAe,GAAGe;AAAzB,WAAd;AACD,SAfD;;AAgBAd,QAAAA,WAAW,CAACsB,KAAZ;AACD;AACD;;;;;;AAIA,YAAMC,QAAQ,GAAG,KAAKjB,KAAL,CAAWE,GAA5B;AACAb,MAAAA,KAAK,CACA6B,IADL,CACU,wBADV,EACmC;AAACD,QAAAA;AAAD,OADnC,EAEKE,IAFL,CAEUjB,GAAG,IAAI;AACXkB,QAAAA,OAAO,CAACC,GAAR,CAAY,MAAZ,EAAmBnB,GAAnB;AAED,OALL;AAMD,KAlCmC;AAAA;;AAmCpCoB,EAAAA,MAAM,GAAG;AACPF,IAAAA,OAAO,CAACC,GAAR,CAAY,KAAKrB,KAAL,CAAWE,GAAvB;AAEA,WACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,MAAD;AACE,MAAA,OAAO,EAAE,CAAC,KAAKF,KAAL,CAAWC,OAAZ,GAAsB,cAAtB,GAAuC,WADlD;AAEE,MAAA,IAAI,EAAC,YAFP;AAGE,MAAA,KAAK,EAAE,CAAC,KAAKD,KAAL,CAAWC,OAAZ,GAAsB,MAAtB,GAA+B,KAHxC;AAIE,MAAA,aAAa,EAAC,MAJhB;AAKE,MAAA,OAAO,EAAE,KAAKE,UALhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,EAQE,oBAAC,OAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,OAAD,CAAS,MAAT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBADF,EAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAI,KAAKH,KAAL,CAAWE,GAAf,CAFF,CARF,CADF;AAeD;;AArDmC;AAwDtC,eAAeH,MAAf","sourcesContent":["import React, { Component } from \"react\";\nimport { Button, Message } from \"semantic-ui-react\";\nimport axios from 'axios'\n\nwindow.SpeechRecognition =\n  window.webkitSpeechRecognition || window.SpeechRecognition;\nlet finalTranscript = \"\";\nlet recognition = new window.SpeechRecognition();\nrecognition.lang = \"en-US\";\nrecognition.lang = \"th-TH\";\nrecognition.interimResults = true;\nrecognition.maxAlternatives = 10;\nrecognition.continuous = true;\nexport class Speech extends Component {\n  state = { pressed: false, res: \"\" };\n  btnPressed = () => {\n    this.setState({ pressed: !this.state.pressed });\n    if (window.hasOwnProperty('webkitSpeechRecognition')) {\n      recognition.onresult = event => {\n        let interimTranscript = \"\";\n        for (\n          let i = event.resultIndex, len = event.results.length;\n          i < len;\n          i++\n        ) {\n          let transcript = event.results[i][0].transcript;\n          if (event.results[i].isFinal) {\n            finalTranscript += transcript;\n          } else {\n            interimTranscript += transcript;\n          }\n        }\n        this.setState({ res: finalTranscript + interimTranscript });\n      };\n      recognition.start();\n    }\n    /*else{\n      recognition.stop();\n      alert(\"Stop recording\")\n    }*/\n    const sendData = this.state.res\n    axios\n        .post(\"http://127.0.0.1:5000/\",{sendData} )\n        .then(res => {\n          console.log(\"####\",res);\n          \n        });\n  };\n  render() {\n    console.log(this.state.res);\n    \n    return (\n      <div>\n        <Button\n          content={!this.state.pressed ? \"Start Record\" : \"Recording\"}\n          icon=\"microphone\"\n          color={!this.state.pressed ? \"teal\" : \"red\"}\n          labelPosition=\"left\"\n          onClick={this.btnPressed}\n        />\n        <Message>\n          <Message.Header>Result</Message.Header>\n          <p>{this.state.res}</p>\n        </Message>\n      </div>\n    );\n  }\n}\n\nexport default Speech;\n"]},"metadata":{},"sourceType":"module"}